{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)  #so we have 10 unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer = 'rmsprop',\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data into the shape the network expects\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/np.max(train_images) #converting the arrays to flaot and then in values between 0 and 1\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255 #because we know the max value is 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)  #converting to categorical so that network doesn not find any pattern because they are in numbers\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2579 - acc: 0.9264\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1038 - acc: 0.9694\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0682 - acc: 0.9795\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0492 - acc: 0.9854\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0378 - acc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6e05a67f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now training the model\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 42us/step\n",
      "test accuracy : 0.9794\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test accuracy :', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now using tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'tanh', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer = 'rmsprop',\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/np.max(train_images) #converting the arrays to flaot and then in values between 0 and 1\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255 #because we know the max value is 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)  #converting to categorical so that network doesn not find any pattern because they are in numbers\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3354 - acc: 0.9019\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1755 - acc: 0.9484\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1165 - acc: 0.9656\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0850 - acc: 0.9748\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0651 - acc: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d680b65828>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now training the model\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/step\n",
      "test accuracy : 0.9743\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test accuracy :', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sigmoid as Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'sigmoid', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer = 'rmsprop',\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/np.max(train_images) #converting the arrays to flaot and then in values between 0 and 1\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255 #because we know the max value is 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)  #converting to categorical so that network doesn not find any pattern because they are in numbers\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.4285 - acc: 0.8839\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2353 - acc: 0.9314\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1778 - acc: 0.9480\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1391 - acc: 0.9596\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1125 - acc: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d683de7ac8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now training the model\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n",
      "test accuracy : 0.9663\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test accuracy :', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the Above Experiment , The Activation Function \"relu\" gives the most efficient result on the unseen data given that the other conditions of the model are same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with the relu function using a validation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer = 'rmsprop',\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/np.max(train_images) #converting the arrays to flaot and then in values between 0 and 1\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255 #because we know the max value is 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)  #converting to categorical so that network doesn not find any pattern because they are in numbers\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.2797 - acc: 0.9198 - val_loss: 0.1520 - val_acc: 0.9573\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.1165 - acc: 0.9657 - val_loss: 0.1161 - val_acc: 0.9658\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0778 - acc: 0.9771 - val_loss: 0.0896 - val_acc: 0.9739\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.0550 - acc: 0.9838 - val_loss: 0.0739 - val_acc: 0.9783\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.0409 - acc: 0.9878 - val_loss: 0.0792 - val_acc: 0.9765\n"
     ]
    }
   ],
   "source": [
    "x_val = train_images[:10000]\n",
    "partial_x_train = train_images[10000:]\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "#Now training the model\n",
    "history = network.fit(partial_x_train,\n",
    "            partial_y_train, \n",
    "            epochs=5, \n",
    "            batch_size=128,\n",
    "            validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(history_dict['acc'])+1)\n",
    "plt.plot(epochs, loss_values, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
